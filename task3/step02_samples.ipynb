{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de13dd52",
   "metadata": {},
   "source": [
    "## Sampling documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "DPT_S = \"[dptment_start]---------------\"\n",
    "DPT_E = \"[dptment_end]---------------\"\n",
    "DOC_S = \"[doc_start]---------------\"\n",
    "DOC_E = \"[doc_end]---------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_category = [\"visits_2011to2020\"]\n",
    "\n",
    "all_pts = []\n",
    "path = \"./data\"\n",
    "for d in range(len(data_category)):\n",
    "    print(\"data_category[d]: \", data_category[d])\n",
    "    target_folder = path +\"/\"+ data_category[d]\n",
    "    data_folders = glob.glob(target_folder+\"/*\")\n",
    "    data_folders.sort()\n",
    "    \n",
    "    for f in range(len(data_folders)):\n",
    "        group = data_folders[f]\n",
    "        pateints = glob.glob(group+\"/*.txt\")\n",
    "#         print(\"group: \", group)\n",
    "        \n",
    "        for p in range(len(pateints)):\n",
    "            if pateints[p] not in all_pts:\n",
    "                all_pts.append(pateints[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eead839",
   "metadata": {},
   "source": [
    "## get patient_pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_pools(path):\n",
    "    file = open(path)\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    _pts = []\n",
    "\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        _pts.append(line.split(\"/\")[-1].split(\".\")[0])\n",
    "    return _pts\n",
    "\n",
    "\n",
    "train_pts = get_patient_pools(\"../preprocessing/01_data4finetune/pts_SNUH_visit_2011to2020_heldout_train.txt\")\n",
    "test_pts = get_patient_pools(\"../preprocessing/01_data4finetune/pts_SNUH_visit_2011to2020_heldout_test.txt\")\n",
    "\n",
    "print(\"len(train_pts): \", len(train_pts))\n",
    "print(\"len(test_pts): \", len(test_pts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdedaf",
   "metadata": {},
   "source": [
    "## set Department\n",
    "- ['내분비대사내과', '호흡기내과', '순환기내과', '소화기내과', '류마티스내과', '신장내과', '알레르기내과', '감염내과']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments = ['내분비대사내과', '호흡기내과', '순환기내과', '소화기내과', '류마티스내과', '신장내과', '알레르기내과', '감염내과']\n",
    "file = open(\"./data/departments.txt\", \"w\")\n",
    "file.write(\"\\n\".join(departments))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments = []\n",
    "\n",
    "for p in range(len(all_pts)):\n",
    "    file = open(all_pts[p], \"r\")\n",
    "    lines = file.readlines()\n",
    "    patient_num =all_pts[p].split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    if p%500==0:\n",
    "        print(str(p) +\"/\"+str(len(all_pts)))\n",
    "    \n",
    "    dpts = []\n",
    "    documents = []\n",
    "    doc = []\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        if line == DPT_S:\n",
    "            mode = \"read_dpt\"\n",
    "        \n",
    "        elif line == DPT_E:\n",
    "            #if line not in dpts:\n",
    "            dpts.append(line)\n",
    "        \n",
    "        elif line == DOC_S:\n",
    "            mode = \"read_doc\"\n",
    "            \n",
    "        else:\n",
    "            if mode == \"read_dpt\":\n",
    "                if line not in departments:\n",
    "                    departments.append(line)\n",
    "        \n",
    "print(\"departments: \", departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(departments): \", len(departments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036749a",
   "metadata": {},
   "source": [
    "### read documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/departments.txt\", \"r\")\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "label_i_to_w = {}\n",
    "label_w_to_i = {}\n",
    "for l in range(len(lines)):\n",
    "    label_i_to_w[l] = lines[l].strip(\"\\n\")\n",
    "    label_w_to_i[lines[l].strip(\"\\n\")] = l \n",
    "print(label_i_to_w)\n",
    "print(label_w_to_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d465b7",
   "metadata": {},
   "source": [
    "## read documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docperfile = 50\n",
    "def get_documents_of_dpt(ptsnums):\n",
    "    department_docs = {}\n",
    "\n",
    "    print(\"len(ptsnums): \", len(ptsnums))\n",
    "    \n",
    "    for t in range(len(ptsnums)):\n",
    "#         print(\"ptsnums[t]: \", ptsnums[t])\n",
    "        \n",
    "        for n in range(len(ptsnums[t])):\n",
    "            if ptsnums[t]!='0':\n",
    "                ptnum_int = int(ptsnums[t][n:])\n",
    "                break\n",
    "#         print('ptnum_int: ', ptnum_int)\n",
    "        \n",
    "        target_group = str(((ptnum_int//docperfile)+1)*docperfile)\n",
    "#         print(\"target_group: \", target_group)\n",
    "        \n",
    "        target_path = \"./data/visits_2011to2020/\"+str(target_group)+\"/\"+str(ptsnums[t])+\".txt\"\n",
    "        print(\"target_path: \", target_path)\n",
    "        \n",
    "        file = open(target_path, \"r\")\n",
    "        lines = file.readlines()\n",
    "        file.close()        \n",
    "\n",
    "        dpts = []\n",
    "        documents = []\n",
    "        doc = []\n",
    "        department = \"\"\n",
    "        for l in range(len(lines)):\n",
    "            line = lines[l].strip(\"\\n\")\n",
    "            if line == DPT_S:\n",
    "                mode = \"read_dpt\"\n",
    "            elif line == DPT_E:\n",
    "                mode = \"\"\n",
    "                \n",
    "            elif line == DOC_S:\n",
    "                mode = \"read_doc\"\n",
    "\n",
    "            elif line == DOC_E:\n",
    "                mode = \"\"\n",
    "                if department in department_docs:\n",
    "                    tmp_docs = department_docs[department]\n",
    "                    tmp_docs.append(doc)\n",
    "                    department_docs[department] = tmp_docs\n",
    "                else:\n",
    "                    department_docs[department] = [doc]\n",
    "\n",
    "                #documents.append(doc)\n",
    "                doc = []\n",
    "\n",
    "            else:\n",
    "                if mode==\"read_doc\":\n",
    "                    doc.append(line)\n",
    "                elif mode==\"read_dpt\":\n",
    "                    department = line\n",
    "                    \n",
    "    return department_docs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rng\n",
    "\n",
    "limit_patients = 1000\n",
    "rng.shuffle(train_pts)\n",
    "train_pts = train_pts[:limit_patients]\n",
    "\n",
    "limit_patients = 100\n",
    "rng.shuffle(test_pts)\n",
    "test_pts = test_pts[:limit_patients]\n",
    "\n",
    "docs_train = get_documents_of_dpt(ptsnums=train_pts)\n",
    "docs_test  = get_documents_of_dpt(ptsnums=test_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5411611",
   "metadata": {},
   "source": [
    "## 샘플 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rng\n",
    "\n",
    "print(label_i_to_w)\n",
    "print(label_w_to_i)\n",
    "\n",
    "\n",
    "\n",
    "def sampling_data(docs_arrays, samplenum = 1000, dup=5, output_directory=\"./data/\"):\n",
    "    gen_sample_num = 0\n",
    "    \n",
    "    print(\"output_directory: \", output_directory)\n",
    "    outpath = output_directory.split(\"/\")[:-1]\n",
    "    outpath = \"/\".join(outpath)\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    outtext = []\n",
    "    for e in range(len(label_i_to_w)):\n",
    "        dpt = label_i_to_w[e]\n",
    "        print(\"dpt: \", dpt)\n",
    "\n",
    "        docs = docs_arrays[dpt]\n",
    "\n",
    "        for s in range(samplenum):\n",
    "            for _ in range(dup):\n",
    "                target1 = rng.randint(0, len(docs)-1)\n",
    "                doc1 = \" \".join(docs[target1])\n",
    "                label = e\n",
    "                \n",
    "                gen_sample_num = gen_sample_num + 1\n",
    "            \n",
    "                outtext.append(str(dpt)+\"\\t\"+str(label)+\"\\t\"+str(doc1))\n",
    "                               #+\"\\t\"+str(doc2))\n",
    "\n",
    "    rng.shuffle(outtext)\n",
    "    \n",
    "    file = open(output_directory, \"w\")\n",
    "    file.write(\"\\n\".join(outtext))\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "    rng.shuffle(outtext)\n",
    "    \n",
    "    file = open(output_directory+\"+info.txt\", \"w\")\n",
    "    file.write(str(gen_sample_num))\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "# sampling train\n",
    "sampling_data(docs_arrays=docs_train, samplenum=1000, dup=1, output_directory=\"./data/train.txt\")\n",
    "\n",
    "# sampling test\n",
    "sampling_data(docs_arrays=docs_test, samplenum=200, dup=1, output_directory=\"./data/test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362cbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d81c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464defd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461615d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
