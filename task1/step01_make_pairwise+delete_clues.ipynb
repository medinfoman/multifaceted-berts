{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6c072f",
   "metadata": {},
   "source": [
    "# Med NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b79bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "randseed = random.randint(1, 1000)\n",
    "print(\"randseed: \", randseed)\n",
    "rng = random.Random(randseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70ca6a",
   "metadata": {},
   "source": [
    "## make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e351b28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_patient(path):\n",
    "    file = open(path, \"r\")\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    documents = []\n",
    "    document = []\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        if line==\"\":\n",
    "            documents.append(\" \".join(document))\n",
    "            document = []\n",
    "        else:\n",
    "            document.append(line)            \n",
    "    \n",
    "    return documents\n",
    "\n",
    "###################################\n",
    "def create_samples(ptnums, \n",
    "                   category, \n",
    "                   dup = 2, \n",
    "                   limit_len = 300, random_samples=10, \n",
    "                   out_directory = \"./data/\", \n",
    "                   outfilename = \"train.txt\"):\n",
    "    outtext = []\n",
    "    \n",
    "    rng.shuffle(ptnums)\n",
    "    ptnums = ptnums[:random_samples]\n",
    "    print(\"len(ptnums): \", len(ptnums))\n",
    "\n",
    "    documents = []\n",
    "    for p in range(len(ptnums)):\n",
    "        documents.append(read_patient(ptnums[p]))\n",
    "        \n",
    "    \n",
    "    if not os.path.exists(out_directory):\n",
    "        os.makedirs(out_directory)\n",
    "    \n",
    "    if \"train\" in outfilename:\n",
    "        file = open(out_directory+\"/train_info.txt\", \"w\")\n",
    "        file.write(str(len(documents)))\n",
    "        file.close()\n",
    "        \n",
    "    elif \"test\" in outfilename:\n",
    "        file = open(out_directory+\"/test_info.txt\", \"w\")\n",
    "        file.write(str(len(documents)))\n",
    "        file.close()\n",
    "\n",
    "    \n",
    "    for t in range(len(ptnums)):\n",
    "        print(\"ptnums[t]: \", ptnums[t])\n",
    "        \n",
    "        pat1 = t\n",
    "        doc1 = rng.randint(0, len(documents[pat1])-1)\n",
    "        doc2 = rng.randint(0, len(documents[pat1])-1)\n",
    "        label = 0\n",
    "        outtext.append(category+\"\\t\"+str(pat1)+\"\\t\"+str(pat1)+\"\\t\"+\n",
    "                   str(label)+\"\\t\"+documents[pat1][doc1]+\"\\t\"+documents[pat1][doc2])\n",
    "        \n",
    "        # ther other patient record \n",
    "        while(True):\n",
    "            pat2 = random.randint(0, len(ptnums)-1)\n",
    "            if pat1!=pat2:\n",
    "                break\n",
    "        \n",
    "        doc1 = rng.randint(0, len(documents[pat1])-1)\n",
    "        doc2 = rng.randint(0, len(documents[pat2])-1)\n",
    "        label = 1\n",
    "        outtext.append(category+\"\\t\"+str(pat1)+\"\\t\"+str(pat2)+\"\\t\"+\n",
    "                   str(label)+\"\\t\"+documents[pat1][doc1]+\"\\t\"+documents[pat2][doc2])\n",
    "        \n",
    "        \n",
    "        # write\n",
    "        if not os.path.exists(out_directory):\n",
    "            os.makedirs(out_directory)\n",
    "        file = open(out_directory+\"/\"+outfilename, \"a\")\n",
    "        file.write(\"\\n\".join(outtext)+\"\\n\")\n",
    "        outtext = []\n",
    "        file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = \"./../preprocessing/01_data4finetune\"\n",
    "train_paths = [\"pts_SNUH_visit_2011to2020_heldout_train.txt\"]\n",
    "test_paths = [\"pts_SNUH_visit_2011to2020_heldout_test.txt\"]\n",
    "categories = [\"SNUH_visit_2011to2020\"]\n",
    "\n",
    "dup = 1\n",
    "limit_len = 300\n",
    "\n",
    "for t in range(len(train_paths)):\n",
    "    print(path_input+\"/\"+train_paths[t])\n",
    "    file = open(path_input+\"/\"+train_paths[t], \"r\")\n",
    "    lines = file.readlines()\n",
    "\n",
    "    train_pts = []\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")        \n",
    "        train_pts.append(path_input+\"/\"+line)\n",
    "    file.close()\n",
    "#     print(train_pts)\n",
    "\n",
    "    \n",
    "    test_pts = []\n",
    "    file = open(path_input+\"/\"+test_paths[t], \"r\")\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        test_pts.append(path_input+\"/\"+line)\n",
    "    file.close()\n",
    "    #print(test_pts)\n",
    "\n",
    "    # train dataset\n",
    "    create_samples(ptnums=train_pts, category=categories[t], \n",
    "                   dup = dup, limit_len = limit_len,\n",
    "                   random_samples = 4000, \n",
    "                   out_directory = \"./data/\",\n",
    "                   outfilename = \"train__yet.txt\")\n",
    "\n",
    "    # # test dataset\n",
    "    create_samples(ptnums=test_pts, category=categories[t], \n",
    "                   dup = dup, limit_len = limit_len, \n",
    "                   random_samples = 200, \n",
    "                   out_directory = \"./data/\", \n",
    "                   outfilename = \"test__yet.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de90c0",
   "metadata": {},
   "source": [
    "# Delete clues\n",
    "- Delete text (Document type, Department, Date) which can make task too easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc64f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop_tokens(content):\n",
    "    content = content.split(\" \")\n",
    "#     print(\"content: \", content)\n",
    "    cut_s = 0\n",
    "    for c in range(len(content)):\n",
    "        if content[c]==\"진료일\":\n",
    "            cut_s = c+2\n",
    "            break\n",
    "            \n",
    "    content = content[cut_s:]\n",
    "    content = \" \".join(content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_del_text(in_path, out_path):\n",
    "    file = open(in_path, \"r\")\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    new_lines = []\n",
    "    for l in range(len(lines)):\n",
    "        if (l+1)%1000==0:\n",
    "            print(str(l)+\" / \"+str(len(lines)))\n",
    "        \n",
    "        line = lines[l].split(\"\\t\")\n",
    "        if len(line)<4:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cate = line[0]   # data category\n",
    "            ptnum1 = line[1] # ptnum1\n",
    "            ptnum2 = line[2] # ptnum2\n",
    "            label = line[3]  # label\n",
    "        \n",
    "        except:\n",
    "            print(\"line: \", line)\n",
    "\n",
    "        content1 = del_stop_tokens(line[4].strip(\"\\n\"))\n",
    "        content2 = del_stop_tokens(line[5].strip(\"\\n\"))\n",
    "\n",
    "        new_lines.append(cate+\"\\t\"+ptnum1+\"\\t\"+ptnum2+\"\\t\"+label+\"\\t\"+content1+\"\\t\"+content2)\n",
    "\n",
    "    file = open(out_path, \"w\")\n",
    "    file.write(\"\\n\".join(new_lines))\n",
    "    file.close()\n",
    "    print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_del_text(in_path=\"./data/train__yet.txt\", out_path=\"./data/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_del_text(in_path=\"./data/test__yet.txt\", out_path=\"./data/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bfd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18867c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
