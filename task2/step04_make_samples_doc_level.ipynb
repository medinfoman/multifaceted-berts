{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb24d852",
   "metadata": {},
   "source": [
    "# Make pair samples\n",
    "\n",
    "- procedure\n",
    "    - Data sampling\n",
    "    - Select up to 10 random documents from one patient\n",
    "    - At this time, extract the ap and so parts separately.\n",
    "\n",
    "- output\n",
    "    - The AP part is grouped from [START_AP] to [END_AP]\n",
    "    - The so part consists of label + tab + sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bfc0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #1\n",
    "# ap_doc_num: List of documents with only ap\n",
    "# so_doc_num: List of documents where so exists\n",
    "# none_ap_doc_num: list of documents with only so\n",
    "# soap_doc_num: List of documents containing all soap\n",
    "# docs_ap: AP part text of each document\n",
    "# docs_so: so part text of each document\n",
    "def get_soap(target_path):\n",
    "    START_AP = \"[START_AP]\"\n",
    "    END_AP = \"[END_AP]\"\n",
    "    END_DOC = \"[END_DOC]\"\n",
    "\n",
    "    docs_ap = []\n",
    "    docs_so = []\n",
    "    ap_doc_num = [] # AP doc num\n",
    "    so_doc_num = [] # SO doc num\n",
    "    \n",
    "    mode = \"AP\"\n",
    "    \n",
    "    file = open(target_path, \"r\")\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    doc_id = 0\n",
    "    document = []\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "\n",
    "        # start of AP\n",
    "        if line==START_AP:\n",
    "            document = []\n",
    "            mode = \"AP\"\n",
    "\n",
    "        # end of AP\n",
    "        elif line==END_AP:\n",
    "            if len(document)>0:\n",
    "                ap_doc_num.append(doc_id)\n",
    "            docs_ap.append(document)\n",
    "            document = []\n",
    "            mode = \"SO\"\n",
    "        \n",
    "        # end of DOC\n",
    "        elif line==END_DOC:\n",
    "            if len(document)>0:\n",
    "                so_doc_num.append(doc_id)\n",
    "            docs_so.append(document)\n",
    "            document = []\n",
    "            mode = \"AP\"\n",
    "        \n",
    "        # end of SO\n",
    "        elif line==\"\" or l==len(lines)-1:\n",
    "            document = []\n",
    "            doc_id = doc_id + 1\n",
    "            \n",
    "        # collect a document\n",
    "        else:\n",
    "            if line!=\"\":\n",
    "                document.append(line)\n",
    "\n",
    "\n",
    "    none_ap_doc_num = []\n",
    "    for d in range(doc_id):\n",
    "        if d not in ap_doc_num:\n",
    "            none_ap_doc_num.append(d)\n",
    "            \n",
    "    return ap_doc_num, so_doc_num, none_ap_doc_num, docs_ap, docs_so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a15557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #2\n",
    "import random\n",
    "def random_docs(limit, doc_nums):\n",
    "    randomdocs = []\n",
    "\n",
    "    # use whole contents\n",
    "    if limit >= len(doc_nums):\n",
    "        return doc_nums\n",
    "    \n",
    "    # select random n\n",
    "    else:\n",
    "        while(True):\n",
    "            dc = random.randint(0, len(doc_nums)-1)\n",
    "            if dc not in randomdocs:\n",
    "                randomdocs.append(dc)\n",
    "            if len(randomdocs)>=limit:\n",
    "                break\n",
    "                \n",
    "    # random documents number\n",
    "    target_docnums = []\n",
    "    for r in range(len(randomdocs)):\n",
    "        target_docnums.append(doc_nums[randomdocs[r]])\n",
    "    target_docnums.sort()\n",
    "\n",
    "    return target_docnums\n",
    "\n",
    "# #3\n",
    "# Select m random AP documents and n SO documents from one patient\n",
    "# After that, separate the ap and so parts to obtain them\n",
    "def random_m_ap_n_so(target_path, so_only_proportion=0.5, sample_num_docs=10):\n",
    "    ap_doc_num, so_doc_num, none_ap_doc_num, docs_ap, docs_so = get_soap(target_path)\n",
    "    # print(\"ap_doc_num: \", ap_doc_num)\n",
    "    # print(\"so_doc_num: \", so_doc_num)\n",
    "    # print(\"none_ap_doc_num: \", none_ap_doc_num)\n",
    "    # print(\"docs_ap: \", docs_ap)\n",
    "    # print(\"docs_so: \", docs_so)\n",
    "    \n",
    "    limit_ap = sample_num_docs*(1-so_only_proportion) # 5\n",
    "    limit_non_ap = sample_num_docs - limit_ap\n",
    "    \n",
    "    if len(ap_doc_num)<limit_ap:\n",
    "        limit_ap=len(ap_doc_num)\n",
    "        limit_non_ap = sample_num_docs - limit_ap    \n",
    "    \n",
    "    # Document random sampling\n",
    "    # regulation\n",
    "    # 1.1. If there is no document with AP in the obtained documents for one patient, no sampling is performed.\n",
    "    # If the number of documents for parts other than AP is 0, do not sample\n",
    "    if len(ap_doc_num)==0 or len(so_doc_num)==0:\n",
    "        return [], []\n",
    "    \n",
    "    #1.2. If there are enough AP documents, there seems to be no need to choose and use documents that only have so.\n",
    "    if len(ap_doc_num) > sample_num_docs:\n",
    "        target_docnums_ap = random_docs(sample_num_docs, ap_doc_num)\n",
    "        target_docnums_non_ap = []\n",
    "    \n",
    "    # 1.3. 양쪽 다 원하는 개수의 문서를 가지고 있지 않은 경우에는 모든 문서를 가져와서 사용한다\n",
    "    # 1.4. 양쪽 다 원는 개수의 문서를 가진 경우\n",
    "    # 1.5. 한쪽이라도 문서 개수를 충족하지 못하면 전체 문서를 사용한다\n",
    "    # (단, ap 가 0 인 경우는 위에서 샘플생성 안하기로 함)\n",
    "    \n",
    "    # 1.3. If neither patient has the desired number of documents, all documents are imported and used.\n",
    "    # 1.4. If both patients have the same number of documents\n",
    "    # 1.5. If even one side does not meet the number of documents, the entire document is used.\n",
    "    # (However, if the number of AP is 0, the sample is not created)\n",
    "    else:\n",
    "        target_docnums_ap = random_docs(limit_ap, ap_doc_num)               # AP Documents\n",
    "        target_docnums_non_ap = random_docs(limit_non_ap, none_ap_doc_num)  # None AP docs\n",
    "        \n",
    "#     print(\"target_docnums_ap: \", target_docnums_ap)\n",
    "#     print(\"target_docnums_non_ap: \", target_docnums_non_ap)\n",
    "\n",
    "    # 3. Sampling segments from obtained samples\n",
    "    ap_index = target_docnums_ap\n",
    "    so_index = target_docnums_ap+target_docnums_non_ap\n",
    "    so_index.sort()\n",
    "\n",
    "    ap_sentences = []\n",
    "    so_sentences = []\n",
    "\n",
    "    for a in range(len(ap_index)):\n",
    "        target_idx = ap_index[a]\n",
    "        ap_sentences = ap_sentences + docs_ap[target_idx]\n",
    "\n",
    "    for a in range(len(so_index)):\n",
    "        target_idx = so_index[a]\n",
    "        so_sentences = so_sentences + docs_so[target_idx]\n",
    "\n",
    "    return ap_sentences, so_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac36ef7",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "- Select two different patients\n",
    "- Sample data from 2 patients\n",
    "- Sample example:\n",
    "    - 1 AP section <> 1 SO parts (from Sample data from 2 patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcb0e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_patients(targets, so_only_proportion=0.1, sample_num_docs=10):\n",
    "    START_AP = \"[START_AP]\"\n",
    "    END_AP = \"[END_AP]\"\n",
    "    assert len(targets)>1\n",
    "    \n",
    "    doc_nums = []\n",
    "    labels = []\n",
    "    so_sentences_all = []\n",
    "    \n",
    "    # patient who has AP section\n",
    "    for t in range(1, len(targets)):\n",
    "        print(\"target_path1: \", targets[0])\n",
    "        target_path = targets[0]\n",
    "        ap_sentences_1, so_sentences_1 = random_m_ap_n_so(target_path, \n",
    "                                                          so_only_proportion=so_only_proportion, \n",
    "                                                          sample_num_docs=sample_num_docs)\n",
    "        # print(\"ap_sentences_1: \", ap_sentences_1)\n",
    "        # print(\"so_sentences_1: \", so_sentences_1)\n",
    "        \n",
    "        # If ap_sentences_1 is [], it means that there is no AP part, \n",
    "        # so the patient subject to this sampling is not sampled.\n",
    "        if ap_sentences_1==[]:\n",
    "            print(\"ap_sentences_1 len is 0\")\n",
    "            return None\n",
    "        elif so_sentences_1==[]:\n",
    "            print(\"so_sentences_1 len is 0\")\n",
    "            return None\n",
    "        \n",
    "        so_sentences_all.append(so_sentences_1)\n",
    "        doc_nums.append(0)\n",
    "    \n",
    "    # patients who does not have AP section\n",
    "    for t in range(1, len(targets)):\n",
    "        print(\"target_path2: \", targets[t])\n",
    "        target_path = targets[t]\n",
    "        _, so_sentences_ = random_m_ap_n_so(target_path, so_only_proportion=so_only_proportion, \n",
    "                                           sample_num_docs=sample_num_docs)\n",
    "        \n",
    "        # The case that needs to regenerate the sample\n",
    "        if len(so_sentences_)==0:\n",
    "            return 2\n",
    "        \n",
    "        so_sentences_all.append(so_sentences_)\n",
    "        doc_nums.append(1)\n",
    "    \n",
    "    \n",
    "    # AP sections\n",
    "    START_AP = \"[START_AP]\"\n",
    "    END_AP = \"[END_AP]\"\n",
    "    ap_text = \"\\n\".join(ap_sentences_1)\n",
    "    ap_text = START_AP +\"\\n\"+ ap_text +\"\\n\"+ END_AP\n",
    "    \n",
    "    print(\"len(so_sentences_all): \", len(so_sentences_all))\n",
    "    print(\"doc_nums: \", doc_nums)\n",
    "    \n",
    "    # SO sections\n",
    "    # The number of sentences retrieved from each patient should be a maximum of 20.\n",
    "    sentnum_limit = 20\n",
    "    for s in range(len(so_sentences_all)):\n",
    "        if len(so_sentences_all[s])>sentnum_limit:\n",
    "            deloop = len(so_sentences_all[s])-sentnum_limit\n",
    "            for d in range(deloop-1, -1, -1):\n",
    "                if random.random()>=0.5:\n",
    "                    del so_sentences_all[s][-1] # Delete the last sentence\n",
    "                else:\n",
    "                    del so_sentences_all[s][0]  # Delete the first sentence\n",
    "    \n",
    "    # Determine the position of the sentence\n",
    "    document_order = [i for i in range(len(so_sentences_all))]\n",
    "    random.shuffle(document_order)\n",
    "    \n",
    "    \n",
    "    print(\"document_order: \", document_order)\n",
    "    \n",
    "    \n",
    "    target_label = 0\n",
    "    if random.randint(0, 9)>=5:\n",
    "        target_label=1\n",
    "    \n",
    "    print(\"target_label: \", target_label)\n",
    "    \n",
    "    so_sentence_cat = []\n",
    "    for d in range(len(document_order)):\n",
    "        idx = document_order[d]\n",
    "        sents = so_sentences_all[idx]\n",
    "        \n",
    "        if target_label==doc_nums[idx]:\n",
    "            so_sentence_cat.append(\"[CLS]\"+\"\\t\"+str(doc_nums[idx])) # labels\n",
    "            for s in range(len(sents)):\n",
    "                so_sentence_cat.append(str(doc_nums[idx])+\"\\t\"+\"\".join(sents[s]))\n",
    "            so_sentence_cat.append(\"[SEP]\")\n",
    "    \n",
    "    \n",
    "    outtext_so = []\n",
    "    for s in range(len(so_sentence_cat)):\n",
    "        outtext_so.append(str(so_sentence_cat[s]))\n",
    "    \n",
    "    outtext = ap_text + \"\\n\" + \"\\n\".join(outtext_so)\n",
    "    \n",
    "    return outtext\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14f6da",
   "metadata": {},
   "source": [
    "## heldouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_path = \"../preprocessing/01_data4finetune/\"\n",
    "\n",
    "train_patients = [\n",
    "    \"pts_SNUH_visit_2011to2020_heldout_train.txt\",\n",
    "]\n",
    "\n",
    "test_patients = [\n",
    "    \"pts_SNUH_visit_2011to2020_heldout_test.txt\",\n",
    "]\n",
    "\n",
    "\n",
    "# heldouts\n",
    "def get_heldouts(heldout_array_files):\n",
    "    heldouts = []\n",
    "    for h in range(len(heldout_array_files)):\n",
    "        file = open(heldout_path +\"/\"+ heldout_array_files[h])\n",
    "        lines = file.readlines()\n",
    "        heldouts_cate = []\n",
    "        for l in range(len(lines)):\n",
    "            pts = lines[l].split(\"/\")[-1]\n",
    "            pts = pts.split(\".\")[0]\n",
    "    #         print(str(pts))\n",
    "            heldouts_cate.append(pts)\n",
    "        heldouts.append(heldouts_cate)\n",
    "    return heldouts\n",
    "\n",
    "train_pts = get_heldouts(train_patients)\n",
    "test_pts = get_heldouts(test_patients)\n",
    "\n",
    "print(\"len(train_pts[0]): \", len(train_pts[0]))\n",
    "print(\"len(test_pts[0]): \", len(test_pts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848a87c",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "categories = [\n",
    "        \"visits_2011to2020\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98839c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patients(category, pts):\n",
    "    docperfile = 50\n",
    "\n",
    "    # train\n",
    "    train_patients = []\n",
    "    \n",
    "    for t in range(len(pts)):\n",
    "        target_patient = pts[t]\n",
    "\n",
    "        zeropoint = 0\n",
    "        for p in range(len(target_patient)):\n",
    "            #print(target_patient[p])\n",
    "            if target_patient[p]!=\"0\":\n",
    "                zeropoint = p\n",
    "                break\n",
    "\n",
    "        pt_id = int(target_patient[zeropoint:])\n",
    "        groupname = str(((pt_id//docperfile)+1)*docperfile)       \n",
    "\n",
    "        target_path = \"./data/03_docsplit/\"+str(category)+\"/\"+str(groupname)+\"/\"+str(target_patient)+\".txt\"\n",
    "\n",
    "        train_patients.append(target_path)\n",
    "        \n",
    "    return train_patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"./data/04_samples\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "def make_samples(pts_nums, categories, mode, dup_factor=2):\n",
    "    \n",
    "    # 생성된 샘플의 개수\n",
    "    num_samples = 0\n",
    "\n",
    "    # 작성한 샘플의 개수\n",
    "    write_count=0\n",
    "    \n",
    "    # 작성 정보\n",
    "    writeinfo = \"\"\n",
    "        \n",
    "    # 루프\n",
    "    for c in range(len(categories)):\n",
    "        category = categories[c]\n",
    "        # Obtain the path to the patient record file\n",
    "        target_patients = get_patients(category, pts_nums[c])\n",
    "        print(\"len(target_patients): \", len(target_patients))\n",
    "        target_patients.sort()\n",
    "\n",
    "        for _ in range(dup_factor):\n",
    "            # 샘플링\n",
    "            for t in range(len(target_patients)):\n",
    "\n",
    "                # 2 random patient records\n",
    "                pat1 = target_patients[t]\n",
    "                while(True):\n",
    "                    pat2 = random.randint(0, len(target_patients)-1)\n",
    "                    pat2 = target_patients[pat2]\n",
    "                    \n",
    "                    if pat1!=pat2:\n",
    "                        outtext = shuffle_patients(targets=[pat1, pat2], \n",
    "                                                   so_only_proportion=0.1, sample_num_docs=10)\n",
    "                        \n",
    "                        # Code number 2 means to restart this code\n",
    "                        # This is the case where there is no label 1 in the obtained so sentence.\n",
    "                        if outtext!=2:\n",
    "                            break\n",
    "\n",
    "                            \n",
    "\n",
    "                if outtext!=None:\n",
    "                    file = open(output_directory+\"/\"+str(mode)+\".txt\", \"a\")\n",
    "                    if write_count==0:\n",
    "                        file.write(outtext)\n",
    "                    else:\n",
    "                        file.write(\"\\n\\n\"+outtext)\n",
    "                    file.close()\n",
    "                    write_count = write_count+1\n",
    "\n",
    "                    \n",
    "        num_samples = num_samples + write_count\n",
    "        print(\"num_samples: \", num_samples)\n",
    "        writeinfo = writeinfo + \"\\n\"+str(mode)+\" samples: \" + str(num_samples) \n",
    "\n",
    "        file = open(\"./data/04_samples/info_\"+str(mode)+\".txt\", \"w\")\n",
    "        file.write(writeinfo)\n",
    "        file.close()\n",
    "\n",
    "make_samples(pts_nums=train_pts, categories=categories, mode=\"train\", dup_factor=4)\n",
    "make_samples(pts_nums=test_pts,  categories=categories, mode=\"test\", dup_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ba8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93fce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
