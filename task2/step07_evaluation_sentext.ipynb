{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df74685f",
   "metadata": {},
   "source": [
    "# NLI eval\n",
    "- we refered code following github: \n",
    "- https://github.com/kamalkraj/BERT-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# mult processing\n",
    "#import torch.multiprocessing as mp\n",
    "\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "from transformers import (WEIGHTS_NAME, AdamW, BertConfig,\n",
    "                          BertForTokenClassification, BertTokenizer,\n",
    "                          get_linear_schedule_with_warmup, \n",
    "                          BertPreTrainedModel, BertModel) # cls classifier 를 위해 로드\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import sequence_labeling # 따로 결과를 뽑아내고 싶음\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "import codecs\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle\n",
    "    \n",
    "import glob\n",
    "import time\n",
    "\n",
    "import easydict\n",
    "\n",
    "import six\n",
    "import tqdm\n",
    "from tqdm import tqdm, trange\n",
    "import collections\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a939be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingInstance(object):\n",
    "    \"\"\"A single training instance (sentence pair).\"\"\"\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, labels, eval_pos):\n",
    "        self.input_ids=input_ids\n",
    "        self.input_mask=input_mask\n",
    "        self.segment_ids=segment_ids \n",
    "        self.labels=labels\n",
    "        self.eval_pos = eval_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c73862",
   "metadata": {},
   "source": [
    "## SO classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SO_classifier(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size*2, 2)         \n",
    "        self.init_weights()\n",
    "        self.loss = torch.nn.BCELoss(reduction='none')\n",
    "        self.actfct = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, label_ids, eval_pos,  # 220513 eval_pos\n",
    "                attention_mask=None, token_type_ids=None,  # 220315 segment_id\n",
    "                position_ids=None, head_mask=None, inputs_embeds=None,\n",
    "                output_attentions=None, output_hidden_states=None,\n",
    "                return_dict=None, split_num=1):\n",
    "        \n",
    "        \n",
    "        outputs = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            position_ids = position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # first [SEP]: AP context\n",
    "        # second~ [SEP]: SO context\n",
    "        sequence_output = outputs[0]\n",
    "        \n",
    "        forward_pos = []        \n",
    "        valid_output = []\n",
    "        valid_labels = []\n",
    "        \n",
    "        ## prediction\n",
    "        for b in range(len(eval_pos)):\n",
    "            ap_point = eval_pos[b][0]            \n",
    "            soap_point = []\n",
    "            for e in range(1, len(eval_pos[b])):\n",
    "                if eval_pos[b][e]==0:\n",
    "                    break\n",
    "                \n",
    "                so_point = eval_pos[b][e]\n",
    "                soap_point.append([ap_point.item(), so_point.item()])\n",
    "                \n",
    "                # ap + so context\n",
    "                pooled = torch.cat([sequence_output[b][ap_point], sequence_output[b][so_point]])\n",
    "                \n",
    "                valid_output.append(pooled)\n",
    "                \n",
    "                # label\n",
    "                valid_labels.append(label_ids[b][e-1].item())\n",
    "            \n",
    "            forward_pos.append(soap_point)\n",
    "        \n",
    "        valid_output = torch.stack(valid_output)\n",
    "        valid_output = valid_output.to(self.device)\n",
    "        \n",
    "        seq_relationship_scores = self.classifier(valid_output)        \n",
    "        \n",
    "        ### one-hot encoding\n",
    "        numerator = 0\n",
    "        denominator = 1e-5\n",
    "        classes = 2\n",
    "        label_hot = torch.zeros(seq_relationship_scores.size())\n",
    "        \n",
    "        for l in range(len(label_hot)):\n",
    "            label = valid_labels[l]\n",
    "            label_hot[l][label] = 1\n",
    "        \n",
    "        label_hot = label_hot.to(self.device)\n",
    "       \n",
    "        # cross entropy\n",
    "        prediction_scores = nn.functional.log_softmax(seq_relationship_scores, dim=-1)\n",
    "        numerator = (-1)* torch.sum(prediction_scores * label_hot)\n",
    "        denominator = torch.sum(label_hot) + 1e-5\n",
    "        \n",
    "        loss = numerator / denominator       \n",
    "        \n",
    "        # probabilities\n",
    "        probs = prediction_scores.detach().cpu()\n",
    "        \n",
    "        # When finetuning, predictions are made according to the number of samples without batch distinction.\n",
    "        # The prediction results of each sample must be reconstructed according to the batch.\n",
    "        count_p = 0\n",
    "        outtext = []\n",
    "        for b in range(len(forward_pos)):\n",
    "            soaploc = forward_pos[b]\n",
    "            tmp_label = []\n",
    "            tmp_pred = []\n",
    "            tmp_props = []\n",
    "            for p in range(len(soaploc)):\n",
    "                tmp_label.append(valid_labels[count_p])\n",
    "                \n",
    "                pred = int(torch.argmax(probs[count_p], dim=-1).item())\n",
    "                tmp_pred.append(pred)\n",
    "                \n",
    "                tmp_props.append([probs[count_p][0].item(), probs[count_p][1].item()])\n",
    "                \n",
    "                outtext.append(\"batch_\"+str(b)+\"\\t\"+str(probs[count_p])+\"\\t\"+str(label_ids[b][p].item())+\"\\t\"+str(pred))\n",
    "                count_p = count_p + 1\n",
    "                \n",
    "        assert count_p==len(probs)\n",
    "        \n",
    "        return loss, outtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddb340",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args):\n",
    "    ############################################################################\n",
    "    ##              Multi-GPUs, Distributed settings\n",
    "    ############################################################################ \n",
    "    if args.local_rank == -1 or args.no_cuda:\n",
    "        #device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "        #n_gpu = torch.cuda.device_count()\n",
    "        device = \"cuda:0\"\n",
    "        n_gpu = 1\n",
    "        \n",
    "    else:\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        device = torch.device(\"cuda\", args.local_rank)\n",
    "        n_gpu = 1\n",
    "        # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "    logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args.local_rank != -1), args.fp16))\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    #              Functions for Dataload (load cache data)\n",
    "    ###############################################################\n",
    "    # 파일 목록 획득\n",
    "    def get_file_arrays(data_path):\n",
    "        data_path = data_path.split(\",\")\n",
    "        print(\"data_path: \", data_path)\n",
    "        \n",
    "        cache_files_all = []\n",
    "        for i in range(len(data_path)):\n",
    "            path = data_path[i].strip()\n",
    "#             print(\"data_path[i]: \", path)\n",
    "            files = glob.glob(path)\n",
    "#             print(\"len(files): \", len(files))\n",
    "            cache_files_all = cache_files_all + files\n",
    "        cache_files_all.sort()\n",
    "        \n",
    "        print(\"Got \" + str(len(cache_files_all)) + \" cache_files\")\n",
    "        \n",
    "        return cache_files_all\n",
    "    \n",
    "    # split file arrays\n",
    "    def split_file_array(cache_files, num_files_on_memory):\n",
    "        cache_file_groups = []\n",
    "        for i in range(0, len(cache_files), num_files_on_memory):\n",
    "            start = i\n",
    "            if (i+num_files_on_memory) < len(cache_files):\n",
    "                end = i+num_files_on_memory\n",
    "            else:\n",
    "                end = len(cache_files)\n",
    "            cache_file_groups.append(cache_files[start:end])                \n",
    "        return cache_file_groups\n",
    "    \n",
    "   # 파일 읽기\n",
    "    def read_files(cache_files_pieces):\n",
    "#         print(\"READING NEXT FILES OF GROUP...\")\n",
    "        eval_features = []\n",
    "        for c in range(len(cache_files_pieces)):\n",
    "            with open(cache_files_pieces[c], 'rb') as input:\n",
    "                eval_features = eval_features + pickle.load(input)\n",
    "            print(\"cache_files_pieces[c]: \", cache_files_pieces[c])\n",
    "        print(\"len(eval_features): \", len(eval_features))        \n",
    "        \n",
    "        # 학습 샘플의 개수\n",
    "        num_eval_examples = len(eval_features)\n",
    "        \n",
    "        #input_ids, input_mask, segment_ids, label_ids, eval_pos\n",
    "        \n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.labels for f in eval_features], dtype=torch.long)\n",
    "        all_eval_pos = torch.tensor([f.eval_pos for f in eval_features], dtype=torch.long)        \n",
    "        \n",
    "        # 반드시 squeeeze 하여 돌릴 것 (쓸데없는 차원떄문에 모델 forward 가 안되는 문제)\n",
    "        all_input_ids = torch.squeeze(all_input_ids)\n",
    "        all_input_mask = torch.squeeze(all_input_mask)\n",
    "        all_segment_ids = torch.squeeze(all_segment_ids)\n",
    "        all_label_ids = torch.squeeze(all_label_ids)\n",
    "        all_eval_pos = torch.squeeze(all_eval_pos)\n",
    "        \n",
    "        \n",
    "        eval_data = TensorDataset(\n",
    "            all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_eval_pos\n",
    "        )\n",
    "        \n",
    "        if args.local_rank == -1:\n",
    "            eval_sampler = RandomSampler(eval_data)\n",
    "        else:\n",
    "            eval_sampler = DistributedSampler(eval_data)\n",
    "        \n",
    "        print(\"len(eval_data): \", len(eval_data))\n",
    "        print(\"args.eval_batch_size: \", args.eval_batch_size)\n",
    "        \n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "        \n",
    "        print(\"len(eval_dataloader): \", len(eval_dataloader))\n",
    "        \n",
    "        return eval_dataloader, num_eval_examples\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    ##                    labels\n",
    "    ############################################################################\n",
    "    label_list = [\"0\", \"1\"] # not extraction, extraction\n",
    "    num_labels = len(label_list) # + 1 NER 에서는 [PAD] 때문에 +1 했었음\n",
    "    \n",
    "\n",
    "    ############################################################################\n",
    "    ##                      Prepare model\n",
    "    ############################################################################\n",
    "    print(\"loading weights from checkpoint (\", args.checkpoint, \")\")\n",
    "    config = BertConfig.from_pretrained(args.checkpoint, num_labels=num_labels)\n",
    "    model = SO_classifier.from_pretrained(args.checkpoint,\n",
    "              from_tf = False,\n",
    "              config = config)\n",
    "    print(\"loaded weights from checkpoint (\", args.checkpoint, \")\")\n",
    "    \n",
    "    if args.local_rank == 0:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "    print(\"device: \", device)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    ############################################################################\n",
    "    ##              Start evalution\n",
    "    ############################################################################\n",
    "    global_step = 0\n",
    "    nb_tr_steps = 0\n",
    "    tr_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    #            Dataload (load cache data) - Train data\n",
    "    ###############################################################\n",
    "    cache_files = get_file_arrays(args.data_dir)\n",
    "    print(\"cache_files: \", cache_files)\n",
    "    \n",
    "    true_pred = 0 # true prediction\n",
    "    true_gold = 0 # true label\n",
    "    \n",
    "    true_positives = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    for c in range(len(cache_files)):\n",
    "        print(\"targetfile: \", cache_files[c])\n",
    "        eval_dataloader, num_eval_examples = read_files([cache_files[c]])\n",
    "        \n",
    "        filename = cache_files[c].split(\"/\")[-1]\n",
    "        \n",
    "        outtext = \"label\\tprediction\\n\"\n",
    "        \n",
    "        for step, batch in enumerate(tqdm(eval_dataloader, desc=\"Iteration\")):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, eval_pos = batch\n",
    "            \n",
    "            loss, probs = model(input_ids=input_ids, label_ids=label_ids, eval_pos=eval_pos, \n",
    "                attention_mask=input_mask, token_type_ids=segment_ids,\n",
    "                position_ids=None, head_mask=None, inputs_embeds=None,\n",
    "                output_attentions=None, output_hidden_states=None,\n",
    "                return_dict=None, split_num=args.split_num)            \n",
    "            \n",
    "            #print(\"probs: \", probs)\n",
    "            outtext = outtext + \"\\n\".join(probs)+\"\\n\"\n",
    "            \n",
    "            num_samples = len(probs)\n",
    "            for b in range(len(probs)):\n",
    "                label = int(probs[b].split(\"\\t\")[-2])\n",
    "                pred  = int(probs[b].split(\"\\t\")[-1])\n",
    "                \n",
    "                # prediction entailed\n",
    "                if pred==0:\n",
    "                    true_pred = true_pred + 1\n",
    "                    \n",
    "                # gold entailed\n",
    "                if label==0:\n",
    "                    true_gold = true_gold + 1\n",
    "                \n",
    "                # true positives (==Positive predictive value = precision)\n",
    "                if label==pred and label==0:\n",
    "                    true_positives = true_positives + 1\n",
    "\n",
    "        # output predictions\n",
    "        if not os.path.exists(args.output_dir+\"/preds/\"):\n",
    "            os.makedirs(args.output_dir+\"/preds/\")\n",
    "        \n",
    "        file = open(args.output_dir+\"/preds/\"+filename[:-len(\".cache\")]+\".txt\", \"w\")\n",
    "        file.write(outtext)\n",
    "        file.close()\n",
    "    \n",
    "        # entailed (same patient) = 0\n",
    "        # different patients = 1\n",
    "        print(\"true_positives: \", true_positives)\n",
    "        print(\"true_pred: \", true_pred)\n",
    "        print(\"true_gold: \", true_gold)\n",
    "        precision = float(true_positives/true_pred)\n",
    "        # true positives / real_true\n",
    "        recall = float(true_positives/true_gold)\n",
    "        f1_score = 2 / ((1/precision) + (1/recall))\n",
    "    \n",
    "        \n",
    "    # output score\n",
    "    file = open(args.output_dir+\"/sentext_f1_score.txt\", \"w\")\n",
    "    \n",
    "    scoretext = \"precision\\trecall\\tf1score\\n\"\n",
    "    scoretext = scoretext+str(precision)+\"\\t\"+str(recall)+\"\\t\"+str(f1_score)\n",
    "    \n",
    "    file.write(scoretext)\n",
    "    file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473aac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    print(\"args.output_dir: \", args.output_dir)\n",
    "    \n",
    "    # check directories\n",
    "    if not args.do_train and not args.do_eval:\n",
    "        raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train:\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "        \n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    \n",
    "    if args.do_train:\n",
    "        train(args)\n",
    "    \n",
    "    if args.do_eval:\n",
    "        evaluate(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886954d0",
   "metadata": {},
   "source": [
    "# Evaluate Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203319c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dirs = [\n",
    "    './cache/bertbase_cased/test/*.cache',    \n",
    "    './cache/mbert_uncased/test/*.cache', \n",
    "    './cache/biobert/test/*.cache',\n",
    "    './cache/kobert/test/*.cache',\n",
    "]\n",
    "\n",
    "checkpoints = [\n",
    "    './finetuned/ver8.1.4_1142642_epoch2/4045',  # bert cased (pretrained on SNUH visit records)\n",
    "    './finetuned/ver9.1.4_521121_epoch2/4045',   # mbert cased (pretrained on SNUH visit records)\n",
    "    './finetuned/ver11.1.4_521079_epoch2/4045',  # biobert (pretrained on SNUH visit records)\n",
    "    './finetuned/ver12.1.4_407013_epoch2/4045',  # kobert (pretrained on SNUH visit records)\n",
    "]\n",
    "\n",
    "assert len(data_dirs)==len(checkpoints)\n",
    "\n",
    "split_nums=[1]*len(checkpoints)\n",
    "\n",
    "assert len(data_dirs)==len(checkpoints)\n",
    "\n",
    "for d in range(len(data_dirs)):\n",
    "    args = easydict.EasyDict({\n",
    "        'data_dir':data_dirs[d],\n",
    "        'eval_batch_size':4,             # train_batch_size/gradient_accumulation_steps\n",
    "        'gradient_accumulation_steps':1,  # become update step\n",
    "        'save_globalstep':1,             \n",
    "        'checkpoint':checkpoints[d],\n",
    "        'output_dir':checkpoints[d],\n",
    "        'split_num':split_nums[d],\n",
    "\n",
    "        'num_files_on_memory':2,\n",
    "\n",
    "        'num_train_epochs':2,\n",
    "        'warmup_proportion':0.5,\n",
    "        'do_train':False,\n",
    "        'do_eval':True,\n",
    "        'do_lower_case':True,\n",
    "        'fp16_allreduce':False,\n",
    "        'seed':42,\n",
    "        'no_cuda':False,\n",
    "        'use_adasum':False,\n",
    "        'learning_rate':0.00005,\n",
    "        'weight_decay':0.01,\n",
    "        'adam_epsilon':1e-8,\n",
    "        'gradient_predivide_factor':1.0,\n",
    "        'fp16':False,\n",
    "        'max_grad_norm':1.0,\n",
    "        'num_files_on_memory':2,\n",
    "        'local_rank':-1,\n",
    "        'fp16_opt_level':'O1',\n",
    "        'loss_scale':0,\n",
    "        'server_ip':'',\n",
    "        'server_port':'',    \n",
    "        'server_ip':None,\n",
    "        'server_port':None,\n",
    "        'cuda':True,\n",
    "        'vocab_size':30014, # ver1.5~ver2.2\n",
    "        'hidden_size':768,\n",
    "        'num_hidden_layers':12,\n",
    "        'num_attention_heads':12,\n",
    "        'hidden_act':'gelu',\n",
    "        'intermediate_size':3072,\n",
    "        'hidden_dropout_prob':0.1,\n",
    "        'attention_probs_dropout_prob':0.1,\n",
    "        'max_position_embeddings':512,\n",
    "        'type_vocab_size':2,\n",
    "        'initializer_range':0.02,\n",
    "        'layer_norm_eps':1e-12,\n",
    "        'gradient_checkpointing':None,\n",
    "        'position_embedding_type':None,\n",
    "        'use_cache':None,\n",
    "        'classifier_dropout':None,\n",
    "\n",
    "        'max_seq_length':512\n",
    "    })\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1dbba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d515d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
