{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6a544d",
   "metadata": {},
   "source": [
    "# index the Sections\n",
    "\n",
    "## 주의점\n",
    "- 의료문서는 history, P/E & Lab, Assessment, Plan 섹션으로 구성되어 있다.\n",
    "- Task 4 and 5 의 목적은 assessment 의 구간을 찾아내는 task 이다.\n",
    "- Task 4 는 섹션의 순서를 섞고, task 5 에서는 섹션의 순서가 고정된다.\n",
    "- 주의점: task 4 의 섹션의 순서를 섞는 내용은 이 코드에 반영되지 않았다. 우리가 병원정보시스템에서 획득한 데이터는 섹션의 순서가 이미 섞여있었기 때문이다. 만일 당신의 데이터가 섹션의 순서를 섞는 것을 원한다면 이 코드에 입력되는 데이터의 섹션을 미리 섞거나 아래 코드에서 섹션을 섞는 코드를 추가해야한다. \n",
    "\n",
    "\n",
    "## NOTE\n",
    "- Clinical notes consist of history, P/E & Lab, Assessment, and Plan section.\n",
    "- The purpose of Tasks 4 and 5 is to find the range of assessment section.\n",
    "- Task 4 the order of sections was randomized, and in task 5, the order of sections was fixed.\n",
    "- <b>Note: Shuffling the order of sections in task 4 is not reflected in our code. This is because the order of sections in the data we obtained from the hospital information system was already shuffled. If you want your data to shuffled the order of the sections, you must pre-shuffle the sections of the data entered in this code or add the code to shuffle the sections in the code below.</b>\n",
    "\n",
    "\n",
    "## output\n",
    "- In the code below, the order of sections is indexed as follows.\n",
    "    - samplenumber \\t startline1/endline2/Document1 species/section1 species \\t startline2/endline2/Document2 species/section2 species ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789d5b",
   "metadata": {},
   "source": [
    "## heldouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_path = \"../preprocessing/01_data4finetune/\"\n",
    "\n",
    "train_patients = [\n",
    "    \"pts_SNUH_visit_2011to2020_heldout_train.txt\",\n",
    "]\n",
    "\n",
    "test_patients = [\n",
    "    \"pts_SNUH_visit_2011to2020_heldout_test.txt\",\n",
    "]\n",
    "\n",
    "\n",
    "# heldouts\n",
    "def get_heldouts(heldout_array_files):\n",
    "    heldouts = []\n",
    "    for h in range(len(heldout_array_files)):\n",
    "        file = open(heldout_path +\"/\"+ heldout_array_files[h])\n",
    "        lines = file.readlines()\n",
    "        heldouts_cate = []\n",
    "        for l in range(len(lines)):\n",
    "            pts = lines[l].split(\"/\")[-1]\n",
    "            pts = pts.split(\".\")[0]\n",
    "    #         print(str(pts))\n",
    "            heldouts_cate.append(pts)\n",
    "        heldouts.append(heldouts_cate)\n",
    "    return heldouts\n",
    "\n",
    "train_pts = get_heldouts(train_patients)\n",
    "test_pts = get_heldouts(test_patients)\n",
    "\n",
    "print(\"len(train_pts[0]): \", len(train_pts[0]))\n",
    "print(\"len(test_pts[0]): \", len(test_pts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780a0e3",
   "metadata": {},
   "source": [
    "## section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_types_paths = [\"./data/02_type_to_file_links/sections_visits_2011to2020_task4.txt\"]\n",
    "\n",
    "section_types = {}\n",
    "for i in range(len(section_types_paths)):\n",
    "    section_types_path = section_types_paths[i]\n",
    "    file = open(section_types_path, \"r\")\n",
    "    lines = file.readlines()\n",
    "    for l in range(len(lines)):\n",
    "        if lines[l]==\"\\n\":\n",
    "            continue\n",
    "        doctype = lines[l].split(\"\\t\")[0].strip(\"\\n\")\n",
    "        section = lines[l].split(\"\\t\")[1].strip(\"\\n\")    \n",
    "        key = doctype+\"\\t\"+section\n",
    "\n",
    "        val = lines[l].split(\"\\t\")[2].strip(\"\\n\")\n",
    "        \n",
    "        if \"assessment\" in val.lower():\n",
    "            section_types[key] = \"assessment\"\n",
    "        else:\n",
    "            section_types[key] = \"else\"\n",
    "                \n",
    "    file.close()\n",
    "print(section_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac339d2",
   "metadata": {},
   "source": [
    "## indexing\n",
    "\n",
    "- output \n",
    "    - samplenumber \\t startline1/endline2/Document1 species/section1 species \\t startline2/endline2/Document2 species/section2 species ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55569aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def linenum_indexing(path, out_folder):\n",
    "    file = open(path, \"r\")\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    filename = path.split(\"/\")[-1]\n",
    "    groupname = path.split(\"/\")[-2]\n",
    "    \n",
    "    documentidx = []\n",
    "    documentidx_line = []\n",
    "    \n",
    "    date_last = \"\"\n",
    "    doctype_last = \"\"\n",
    "    soap_last = \"\"\n",
    "    doc_id_last = \"\"\n",
    "    section_last = \"\"\n",
    "    \n",
    "    start = 0\n",
    "    doc_id = 0\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        if len(line.split(\"\\t\"))<4:\n",
    "            continue\n",
    "        date = line.split(\"\\t\")[0]\n",
    "        doctype = line.split(\"\\t\")[1]\n",
    "        section = line.split(\"\\t\")[2]\n",
    "        content = line.split(\"\\t\")[3]\n",
    "        \n",
    "        key = doctype+\"\\t\"+section\n",
    "        \n",
    "        # switched section\n",
    "        if (section_last!=section or date_last!=date or doctype_last!=doctype) and l!=0:\n",
    "            indx = str(start)+\"/\"+str(l-1)+\"/[DOC]\"+str(doctype_last)+\"/[SEC]\"+str(section_last)\n",
    "            documentidx_line.append(indx)\n",
    "            start = l\n",
    "        \n",
    "        # swithced document\n",
    "        if (date_last!=date or doctype_last!=doctype) and l!=0:\n",
    "            doc_id_last_txt = \"\".join([\"0\"]*(4-len(str(doc_id_last))))+str(doc_id_last)\n",
    "            documentidx.append(str(doc_id_last_txt)+\"\\t\"+\"\\t\".join(documentidx_line))\n",
    "            doc_id = doc_id + 1\n",
    "            documentidx_line = []\n",
    "            \n",
    "            \n",
    "        \n",
    "        date_last = date\n",
    "        doctype_last = doctype\n",
    "        doc_id_last = doc_id\n",
    "        section_last = section\n",
    "        \n",
    "    # rest of data\n",
    "    indx = str(start)+\"/\"+str(l-1)+\"/[DOC]\"+str(doctype_last)+\"/[SEC]\"+str(section_last)\n",
    "    documentidx_line.append(indx)\n",
    "    \n",
    "    doc_id_last_txt = \"\".join([\"0\"]*(4-len(str(doc_id_last))))+str(doc_id_last)\n",
    "    documentidx.append(str(doc_id_last_txt)+\"\\t\"+\"\\t\".join(documentidx_line))\n",
    "    \n",
    "    file = open(out_folder+\"/\"+filename, \"w\")\n",
    "    file.write(\"\\n\".join(documentidx))\n",
    "    file.close()\n",
    "    \n",
    "    return documentidx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b92eed",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "out_folder = \"./data/03_soap_index/train\"\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228ec09",
   "metadata": {},
   "source": [
    "### index data for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "docperfile = 50\n",
    "\n",
    "categories = [\n",
    "    \"visits_2011to2020\",\n",
    "]\n",
    "\n",
    "for c in range(len(categories)):\n",
    "    category = categories[c]\n",
    "    \n",
    "    for t in range(len(train_pts[c])):\n",
    "        target_patient = train_pts[c][t]\n",
    "        print(\"target_patient: \", train_pts[c][t])\n",
    "        \n",
    "        zeropoint = 0\n",
    "        for p in range(len(target_patient)):\n",
    "            #print(target_patient[p])\n",
    "            if target_patient[p]!=\"0\":\n",
    "                zeropoint = p\n",
    "                break\n",
    "        \n",
    "        pt_id = int(target_patient[zeropoint:])\n",
    "        #print(\"pt_id: \", pt_id)\n",
    "        groupname = str(((pt_id//docperfile)+1)*docperfile)       \n",
    "        \n",
    "        #target_path = \"./data/\"+str(category)+\"/\"+str(groupname)+\"/\"+str(target_patient)+\".txt\"\n",
    "        target_path = \"../task2/data/\"+str(category)+\"/\"+str(groupname)+\"/\"+str(target_patient)+\".txt\"\n",
    "        \n",
    "        print(\"target_path :\", target_path)\n",
    "        \n",
    "        linenum_indexing(target_path, out_folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382127",
   "metadata": {},
   "source": [
    "### index data for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a729274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "out_folder = \"./data/03_soap_index/test\"\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "    \n",
    "docperfile = 50\n",
    "\n",
    "categories = [\n",
    "    \"visits_2011to2020\",\n",
    "]\n",
    "\n",
    "for c in range(len(categories)):\n",
    "    category = categories[c]\n",
    "    \n",
    "    for t in range(len(test_pts[c])):\n",
    "        target_patient = test_pts[c][t]\n",
    "        print(\"target_patient: \", test_pts[c][t])\n",
    "        \n",
    "        zeropoint = 0\n",
    "        for p in range(len(target_patient)):\n",
    "            #print(target_patient[p])\n",
    "            if target_patient[p]!=\"0\":\n",
    "                zeropoint = p\n",
    "                break\n",
    "        \n",
    "        pt_id = int(target_patient[zeropoint:])\n",
    "        #print(\"pt_id: \", pt_id)\n",
    "        groupname = str(((pt_id//docperfile)+1)*docperfile)       \n",
    "        \n",
    "        target_path = \"../task2/data/\"+str(category)+\"/\"+str(groupname)+\"/\"+str(target_patient)+\".txt\"\n",
    "        print(\"target_path :\", target_path)\n",
    "        \n",
    "        linenum_indexing(target_path, out_folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97538a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
