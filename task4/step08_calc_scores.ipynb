{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd07cb6c",
   "metadata": {},
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import sequence_labeling\n",
    "\n",
    "# bert\n",
    "from tokenization import BertTokenizer\n",
    "import tokenization as tokenization\n",
    "\n",
    "# kobert tokenizer\n",
    "import sentencepiece as spm\n",
    "import six\n",
    "\n",
    "voacb_paths = [\n",
    "    \"../otherberts/mbert_cased\",\n",
    "    \"../otherberts/bertbase_cased\",\n",
    "    \"../otherberts/bioBERT/biobert_v1.1_pubmed\",\n",
    "    \"../otherberts/kobert/models\",\n",
    "]\n",
    "\n",
    "preds_paths = [\n",
    "    \"./finetuned/ver8.1.4_1142642_epoch2/test_pred\",\n",
    "    './finetuned/ver9.1.4_521121_epoch2/test_pred',\n",
    "    './finetuned/ver11.1.4_521079_epoch2/test_pred',\n",
    "    './finetuned/ver12.1.4_407013_epoch2/test_pred',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "assert len(voacb_paths)==len(preds_paths)\n",
    "\n",
    "# vocab_words\n",
    "class Vocab_words(object):\n",
    "    def __init__(self, vocab_file):\n",
    "        self.i_to_w = {}\n",
    "        self.w_to_i = {}\n",
    "        self.getvocab(vocab_file)\n",
    "\n",
    "    def getvocab(self, vocab_file):\n",
    "        f = open(vocab_file, 'r')\n",
    "        lines = f.readlines()\n",
    "        for l in range(len(lines)):\n",
    "            term = lines[l].strip(\"\\n\")\n",
    "            term = convert_to_unicode(term)\n",
    "            self.i_to_w[int(l)] = term\n",
    "            self.w_to_i[term] = int(l)\n",
    "            \n",
    "def convert_to_unicode(text):\n",
    "    \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        elif isinstance(text, unicode):\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "linemap = {\"tokens\":0, \"preds\":1, \"doc_ids\":2, \"sent_ids\":3, \"labels\":4, \n",
    "           \"out_logits_start\":5, \"out_logits_end\":6}\n",
    "print(\"linemap: \", linemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(lines, vocab_path):\n",
    "    \n",
    "    tokens = lines[linemap[\"tokens\"]].strip(\"\\n\").split(\"\\t\")\n",
    "    preds = lines[linemap[\"preds\"]].strip(\"\\n\").split(\"\\t\")\n",
    "    doc_ids = lines[linemap[\"doc_ids\"]].strip(\"\\n\").split(\"\\t\")\n",
    "    sent_ids = lines[linemap[\"sent_ids\"]].strip(\"\\n\").split(\"\\t\")\n",
    "    labels = lines[linemap[\"labels\"]].strip(\"\\n\").split(\"\\t\")\n",
    "    \n",
    "    # vocab\n",
    "    if \"mbert_cased\" in vocab_path.lower():\n",
    "        vocab_file = vocab_path+'/vocab.txt'\n",
    "        tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False, max_len=512)\n",
    "        vocab_words = list(tokenizer.vocab.keys())\n",
    "\n",
    "    elif \"mbert_uncased\" in vocab_path.lower():\n",
    "        vocab_file = vocab_path+'/vocab.txt'\n",
    "        tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False, max_len=512)\n",
    "        vocab_words = list(tokenizer.vocab.keys())\n",
    "        \n",
    "    elif \"bertbase_uncased\" in vocab_path.lower():\n",
    "        vocab_file = vocab_path+'/vocab.txt'\n",
    "        tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=True, max_len=512)\n",
    "        vocab_words = list(tokenizer.vocab.keys())\n",
    "    \n",
    "    elif \"bertbase_cased\" in vocab_path.lower():\n",
    "        vocab_file = vocab_path+'/vocab.txt'\n",
    "        tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=True, max_len=512)\n",
    "        vocab_words = list(tokenizer.vocab.keys())\n",
    "    \n",
    "    elif \"biobert\" in vocab_path.lower():\n",
    "        vocab_file = vocab_path+'/vocab.txt'\n",
    "        tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False, max_len=512)\n",
    "        vocab_words = list(tokenizer.vocab.keys())\n",
    "    \n",
    "    elif \"kobert\" in vocab_path.lower():\n",
    "        vocab_file = \"../otherberts/KoBERT/models/vocab.txt\"\n",
    "        vocab_words = Vocab_words(vocab_file)\n",
    "        \n",
    "        # sptokenizer\n",
    "        spmodel = \"../otherberts/KoBERT/models/spiece.model\"\n",
    "        tokenizer = spm.SentencePieceProcessor()\n",
    "        tokenizer.load(spmodel)\n",
    "\n",
    "    else:\n",
    "        vocab_file = vocab_path+'/vocab.txt'\n",
    "        vocab_words = Vocab_words(vocab_file)\n",
    "        \n",
    "    cut_interval = [0]\n",
    "    last_doc_id = \"\"\n",
    "    \n",
    "    # The training sample contains one section of assessment per document.\n",
    "    for d in range(len(doc_ids)):\n",
    "        doc_id = doc_ids[d]\n",
    "        if last_doc_id!=doc_id and d!=0:\n",
    "            cut_interval.append(d)\n",
    "        last_doc_id = doc_id\n",
    "    cut_interval.append(len(tokens))\n",
    "    \n",
    "    \n",
    "    # document level exact matching\n",
    "    tp = []             # document level evaluation (accuracy)\n",
    "    y_true_one_pt =  [] # token level eval\n",
    "    y_pred_one_pt = []  # token level eval\n",
    "    document_preds = [] # predicted tokens\n",
    "    for d in range(len(cut_interval)-1):\n",
    "        doc_start = cut_interval[d]\n",
    "        doc_end = cut_interval[d+1]\n",
    "        tokens_doc = tokens[doc_start:doc_end]\n",
    "#         print(\"tokens_doc: \", tokens_doc)\n",
    "        \n",
    "        tokens_str = []\n",
    "        label_str  = []\n",
    "        pred_str   = []\n",
    "        \n",
    "        # exact matching eval\n",
    "        preds_doc = preds[doc_start:doc_end]\n",
    "        labels_doc = labels[doc_start:doc_end]\n",
    "        \n",
    "        for t in range(1, len(tokens_doc)):\n",
    "            token_id = int(tokens_doc[t])\n",
    "            if \"mbert_\" in vocab_path.lower():\n",
    "                tokens_str.append(vocab_words[token_id])\n",
    "            elif \"biobert\" in vocab_path.lower():\n",
    "                tokens_str.append(vocab_words[token_id])\n",
    "            elif \"bertbase_\" in vocab_path.lower():\n",
    "                tokens_str.append(vocab_words[token_id])\n",
    "            elif \"kobert\" in vocab_path.lower():\n",
    "                tokens_str.append(vocab_words.i_to_w[token_id])\n",
    "            else:\n",
    "                tokens_str.append(vocab_words.i_to_w[token_id])\n",
    "            label_str.append(str(labels_doc[t]))\n",
    "            pred_str.append(str(preds_doc[t]))\n",
    "        \n",
    "        if len(tokens_str)>0:\n",
    "            # collect documents\n",
    "            document_preds.append(\" \".join(tokens_str))\n",
    "            document_preds.append(\" \".join(label_str))\n",
    "            document_preds.append(\" \".join(pred_str))\n",
    "        \n",
    "        # document level exact matching\n",
    "        preds_doc = preds[doc_start:doc_end]\n",
    "        labels_doc = labels[doc_start:doc_end]\n",
    "        \n",
    "        # clean all matching = true positive\n",
    "        # but we didn't care because it underestimate the model\n",
    "        false_flag = False\n",
    "        for t in range(len(tokens_doc)):\n",
    "            if preds_doc[t]!=labels_doc[t]:\n",
    "                false_flag = True\n",
    "                break\n",
    "        if false_flag==False:\n",
    "            tp.append(1)\n",
    "        else:\n",
    "            tp.append(0)\n",
    "        \n",
    "        \n",
    "        # token level eval - how many tokens were overlapped\n",
    "        for t in range(1, len(tokens_doc)):\n",
    "            y_true_one_pt.append(int(labels_doc[t]))\n",
    "            y_pred_one_pt.append(int(preds_doc[t]))\n",
    "            \n",
    "    \n",
    "    return y_true_one_pt, y_pred_one_pt, tp, document_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_char(tag):\n",
    "    result = []\n",
    "    for t in range(len(tag)):\n",
    "        if tag[t]==1:\n",
    "            result.append([\"B-asmt\"])\n",
    "        elif tag[t]==0:\n",
    "            result.append([\"B-else\"])\n",
    "            \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e265e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in range(len(preds_paths)):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    exact_match = []\n",
    "    \n",
    "    path = preds_paths[p]+\"/*.txt\"\n",
    "    files = glob.glob(path)\n",
    "    files.sort()\n",
    "    \n",
    "    voacb_path = voacb_paths[p]\n",
    "    \n",
    "    outpath = \"./data/scores/test\"\n",
    "    print(\"outpath: \", outpath)\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "        \n",
    "    output_eval_preds = os.path.join(outpath, str(preds_paths[p].split(\"/\")[-2]))\n",
    "    print(\"output_eval_preds: \", output_eval_preds)\n",
    "    if not os.path.exists(output_eval_preds):\n",
    "        os.makedirs(output_eval_preds)\n",
    "    \n",
    "    print(\"path: \", path)\n",
    "    for f in range(len(files)):\n",
    "        if f%100==0:\n",
    "            print(str(f)+\"/\"+str(len(files)))\n",
    "        \n",
    "        file = open(files[f], \"r\")\n",
    "        filename = files[f].split(\"/\")[-1]\n",
    "        lines = file.readlines()\n",
    "        y_true_one_pt, y_pred_one_pt, exact_match, outtext_file = calc_score(lines, voacb_path)\n",
    "        y_true = y_true + y_true_one_pt\n",
    "        y_pred = y_pred + y_pred_one_pt\n",
    "        exact_match = exact_match + exact_match\n",
    "        \n",
    "        file_out = open(output_eval_preds+\"/\"+str(filename), \"w\")\n",
    "        file_out.write(\"\\n\".join(outtext_file))\n",
    "        file_out.close()\n",
    "    \n",
    "    \n",
    "    # token level evaluation\n",
    "    y_true = change_char(y_true)\n",
    "    y_pred = change_char(y_pred)\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    \n",
    "    outpath = \"./data/scores/test\"\n",
    "    print(\"outpath: \", outpath)\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    output_eval_file = os.path.join(outpath, str(preds_paths[p].split(\"/\")[-2]+\".txt\"))\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        writer.write(report)\n",
    "        \n",
    "        \n",
    "    exactmat_accuracy = sum(exact_match)/len(exact_match)\n",
    "    with open(output_eval_file, \"a\") as writer:\n",
    "        writer.write(\"\\nexcat matching accuracy: \"+str(exactmat_accuracy))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf91b0",
   "metadata": {},
   "source": [
    "# merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "filepaths = glob.glob(\"./data/scores/test/*.txt\")\n",
    "filepaths.sort()\n",
    "\n",
    "names = []\n",
    "scores_asmt = []\n",
    "scores_else = []\n",
    "scores_macro = []\n",
    "scores_doc_acc = []\n",
    "for p in range(len(filepaths)):\n",
    "    file = open(filepaths[p], \"r\")\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    filename = \".\".join(filepaths[p].split(\"/\")[-1].split(\".\")[:-1])\n",
    "    #print(\"filename: \", filename)\n",
    "    names.append(filename)\n",
    "    \n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        line = line.replace(\"    \", \"\\t\")\n",
    "        line = line.strip()\n",
    "#         print(\"line:\", line)\n",
    "        \n",
    "        if \"asmt\" in line:\n",
    "            line = \"\\t\".join(line.split(\"\\t\")[1:4])\n",
    "            scores_asmt.append(line)\n",
    "        elif \"else\" in line:\n",
    "            line = \"\\t\".join(line.split(\"\\t\")[1:4])\n",
    "            scores_else.append(line)\n",
    "        elif \"macro\" in line:\n",
    "            line = \"\\t\".join(line.split(\"\\t\")[1:4])\n",
    "            scores_macro.append(line)\n",
    "        elif \"excat matching accuracy\" in line:\n",
    "            line = \"\".join(line.split(\":\")[-1].strip())\n",
    "            scores_doc_acc.append(line)\n",
    "            \n",
    "#     break\n",
    "print(len(names))\n",
    "print(len(scores_asmt))\n",
    "print(len(scores_else))\n",
    "print(len(scores_macro))\n",
    "print(len(scores_doc_acc))\n",
    "\n",
    "outtext = [\"name\\tp_asmt\\tr_asmt\\tf_asmt\\tp_else\\tr_else\\tf_else\\tp_macro\\tr_macro\\tf_macro\\tscores_doc_acc\"]\n",
    "for n in range(len(names)):\n",
    "    print(names[n]+\"\\t\"+scores_asmt[n]+\"\\t\"+scores_else[n]+\"\\t\"+scores_macro[n])\n",
    "    outtext.append(names[n]+\"\\t\"+scores_asmt[n]+\"\\t\"+scores_else[n]+\"\\t\"+scores_macro[n]+\"\\t\"+scores_doc_acc[n])\n",
    "\n",
    "file = open(\"./data/scores/test_score.txt\", \"w\")\n",
    "file.write(\"\\n\".join(outtext))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420c739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f6b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
