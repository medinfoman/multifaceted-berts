{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce7a787",
   "metadata": {},
   "source": [
    "# Get total list of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4401b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "randseed = random.randint(1, 1000)\n",
    "print(\"randseed: \", randseed)\n",
    "rng = random.Random(randseed)\n",
    "\n",
    "data_category = [\"SNUH_visit_2011to2020\"]\n",
    "train_pt_ratio = [4/5]\n",
    "\n",
    "all_pts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../00_data4pretrain/\"\n",
    "for d in range(len(data_category)):\n",
    "    print(\"data_category[d]: \", data_category[d])\n",
    "    target_folder = path + data_category[d]\n",
    "    group_folders = glob.glob(target_folder+\"/*\")\n",
    "    print(\"len(group_folders): \", len(group_folders))\n",
    "    \n",
    "    for f in range(len(group_folders)):\n",
    "        if (f+1)%100==0:\n",
    "            print((f+1), \"/\", len(group_folders))\n",
    "        \n",
    "        group = group_folders[f]\n",
    "        pateints = glob.glob(group+\"/*.txt\")\n",
    "        \n",
    "        for p in range(len(pateints)):\n",
    "            if pateints[p] not in all_pts:\n",
    "                target_category = pateints[p].split(\"/\")[-3]\n",
    "                target_group = pateints[p].split(\"/\")[-2]\n",
    "                target_ptnum = pateints[p].split(\"/\")[-1]\n",
    "                \n",
    "                ptpath = target_category+\"/\"+target_group+\"/\"+target_ptnum\n",
    "                all_pts.append(ptpath)\n",
    "        \n",
    "        \n",
    "    print(\"len(all_pts): \", len(all_pts))\n",
    "    file = open(\"./pts_\"+str(data_category[d])+\".txt\", \"w\")\n",
    "    file.write(\"\\n\".join(all_pts))\n",
    "    file.close()\n",
    "    \n",
    "# set heldout dataset\n",
    "for d in range(len(data_category)):    \n",
    "    file = open(\"./pts_\"+data_category[d]+\".txt\", \"r\")\n",
    "    all_pts = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    all_pts = [ptpath.strip(\"\\n\") for ptpath in all_pts]\n",
    "    \n",
    "    random.shuffle(all_pts)\n",
    "    list_heldoutsets = all_pts[:5000]\n",
    "    file = open(\"./pts_\"+str(data_category[d])+\"_heldout.txt\", \"w\")\n",
    "    file.write(\"\\n\".join(list_heldoutsets))\n",
    "    file.close()\n",
    "    \n",
    "    print(\"heldoutset for finetuning: \", 5000)\n",
    "    \n",
    "    \n",
    "# Move heldout files to here\n",
    "for d in range(len(data_category)):\n",
    "    file = open(\"./pts_\"+str(data_category[d])+\"_heldout.txt\", \"r\")\n",
    "    lines = file.readlines()    \n",
    "    file.close()\n",
    "    \n",
    "    for l in range(len(lines)):\n",
    "        file_in = lines[l].strip(\"\\n\")\n",
    "        file_in = \"../00_data4pretrain/\"+file_in\n",
    "        \n",
    "        # 이동 폴더 만들기\n",
    "        category  = file_in.split(\"/\")[-3]\n",
    "        groupname = file_in.split(\"/\")[-2]\n",
    "        filename  = file_in.split(\"/\")[-1]\n",
    "        \n",
    "        file_out = \"./\"+category+\"/\"+groupname+\"/\"\n",
    "        if not os.path.exists(file_out):\n",
    "            os.makedirs(file_out)\n",
    "        \n",
    "        # 이동\n",
    "        shutil.move(file_in, file_out+\"/\"+filename)\n",
    "        \n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2623df",
   "metadata": {},
   "source": [
    "# Split into Trainset, Test set\n",
    "- 5,000 patients\n",
    "- trainset: 4,000 patients\n",
    "- testset: 1,000 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1956aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "randseed = random.randint(1, 1000)\n",
    "print(\"randseed: \", randseed)\n",
    "rng = random.Random(randseed)\n",
    "\n",
    "data_category = [\"SNUH_visit_2011to2020\"]\n",
    "train_pt_ratio = [4/5]\n",
    "\n",
    "all_pts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b09349",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "for d in range(len(data_category)):\n",
    "    file = open(\"./pts_\"+str(data_category[d])+\"_heldout.txt\", \"r\")\n",
    "    heldout_patients = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    heldout_patients = [h.strip(\"\\n\") for h in heldout_patients]\n",
    "    \n",
    "    random.shuffle(heldout_patients)\n",
    "    \n",
    "    n_trainset = int(len(heldout_patients)*train_pt_ratio[d])\n",
    "    n_testset  = len(heldout_patients) - n_trainset\n",
    "    \n",
    "    train_pts  = heldout_patients[:n_trainset]\n",
    "    test_pts   = heldout_patients[n_trainset:]\n",
    "    \n",
    "    all_pts.sort()\n",
    "    \n",
    "    file = open(\"./pts_\"+str(data_category[d])+\"_heldout_train.txt\", \"w\")\n",
    "    file.write(\"\\n\".join(train_pts))\n",
    "    file.close()\n",
    "    \n",
    "    file = open(\"./pts_\"+str(data_category[d])+\"_heldout_test.txt\", \"w\")\n",
    "    file.write(\"\\n\".join(test_pts))\n",
    "    file.close()\n",
    "    \n",
    "    print(\"└output: ./pts_\"+str(data_category[d])+\".txt\")\n",
    "    print(\"└number of patients: \", len(heldout_patients))\n",
    "    print(\"└number of n_trainset pt: \", len(train_pts))\n",
    "    print(\"└number of n_testset pt: \", len(test_pts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c0096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104186ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
