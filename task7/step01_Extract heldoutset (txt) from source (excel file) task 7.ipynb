{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bf6976",
   "metadata": {},
   "source": [
    "# step01_Extract heldoutset (txt) from source (excel file) task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import preprocessing\n",
    "\n",
    "sources = ['../sources/visits_2011to2020/*.xlsx']\n",
    "\n",
    "DEPARTMENTS = [\"내분비대사내과\", \"호흡기내과\", \"순환기내과\", \"소화기내과\", \"류마티스내과\", \"신장내과\", \"알레르기내과\", \"감염내과\"]\n",
    "\n",
    "docperfile = 50\n",
    "\n",
    "print(\"DEPARTMENTS: \", DEPARTMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heldout patients\n",
    "pools = []\n",
    "train_pool = \"../preprocessing/01_data4finetune/pts_SNUH_visit_2011to2020_heldout_train.txt\"\n",
    "test_pool  = \"../preprocessing/01_data4finetune/pts_SNUH_visit_2011to2020_heldout_test.txt\"\n",
    "\n",
    "def target_ptnums(target_file):\n",
    "    target_pool = []\n",
    "    file = open(target_file, \"r\")\n",
    "    lines = file.readlines()\n",
    "    for l in range(len(lines)):\n",
    "        line = lines[l].strip(\"\\n\")\n",
    "        ptnum = line.split(\"/\")[-1].replace(\".txt\", \"\")\n",
    "        target_pool.append(ptnum)\n",
    "    file.close()\n",
    "    \n",
    "    return target_pool\n",
    "\n",
    "pools_train = target_ptnums(train_pool)\n",
    "pools_test  = target_ptnums(test_pool)\n",
    "pools = pools_train + pools_test\n",
    "print(\"len(pools): \", len(pools))\n",
    "print(pools[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2edb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order of sections (same as in task 5)\n",
    "# sorted_manually.txt\n",
    "section_path = \"./data/02_type_to_file_links/sections_visits_ordered_2011to2020.txt\"\n",
    "file = open(section_path, \"r\")\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "section_to_idx = {}\n",
    "\n",
    "for l in range(len(lines)):\n",
    "    line = lines[l].strip(\"\\n\")\n",
    "    dat = line.split(\"\\t\")\n",
    "    if len(dat)<2:\n",
    "        continue\n",
    "    doctype_ = dat[0]\n",
    "    section_ = dat[1]\n",
    "    target = str(doctype_)+\"\\t\"+str(section_)\n",
    "    section_to_idx[target] = l\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cadef",
   "metadata": {},
   "source": [
    "### Extract heldoutset as .txt file (task 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31751f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in range(len(sources)):\n",
    "    outputdir = sources[s].split(\"/\")[-2]\n",
    "    output_directory = \"./data/\"+str(outputdir)\n",
    "    print(\"output_directory: \", output_directory)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    filenames = glob.glob(sources[s])\n",
    "    filenames.sort()\n",
    "    print(filenames)\n",
    "    \n",
    "    document = {}\n",
    "    for f in range(len(filenames)):\n",
    "        reading_file = filenames[f].split(\"/\")[-1]\n",
    "        print(\"reading_file: \", reading_file)\n",
    "\n",
    "        print(\"reading...\")\n",
    "        ws = pd.read_excel(filenames[f], engine='openpyxl')\n",
    "\n",
    "        print(\"processing...\")\n",
    "        \n",
    "        print(str(f) + \" / \" + str(len(filenames)) + \"...\" + filenames[f])\n",
    "        for row in range(len(ws)):\n",
    "            if (row+1)%1000==0:\n",
    "                print(str(row) + \" / \" + str(len(ws)))\n",
    "            \n",
    "            outtext = []\n",
    "            \n",
    "            pt_id = ws['fake_id'][row]\n",
    "            date = ws['수진(진료)일'][row]\n",
    "            dptment = ws[\"수진(퇴원포함)진료과\"][row]\n",
    "            doctype = ws[\"서식명\"][row]\n",
    "            \n",
    "            doctype = preprocessing.text_preprocessing(doctype)        \n",
    "            doctype = \"\".join(doctype)\n",
    "            doctype = doctype.replace(\"\\n\", \" \")\n",
    "            \n",
    "            section = ws['서식항목명'][row]\n",
    "            section = preprocessing.text_preprocessing(section)\n",
    "            section = \"\".join(section)\n",
    "            section = section.replace(\"\\n\", \" \")\n",
    "            \n",
    "            \n",
    "            if len(document)>0:    \n",
    "                if (date != date_last or dptment!=dptment_last or pt_id!=pt_id_last or \\\n",
    "                    doctype!=doctype_last):\n",
    "                    \n",
    "                    zeros = \"\".join([\"0\"]*(8-len(str(pt_id_last))))\n",
    "                    pt_id_str = zeros + str(pt_id_last)\n",
    "                    \n",
    "                    # patient id was not in heldout set pool\n",
    "                    if pt_id_str not in pools:\n",
    "                        \"\"\"pt_id_current_str is not in heldout set pool\"\"\"\n",
    "                        document = {}\n",
    "                    \n",
    "                    # patient id was in heldout set pool\n",
    "                    else:\n",
    "                        # output\n",
    "                        date_last_str = preprocessing.text_preprocessing(date_last)\n",
    "                        date_last_str = \"\".join(date_last_str)\n",
    "                        date_last_str = date_last_str.replace(\"\\n\", \" \")                    \n",
    "                        document_list = [\"DATE [ \" + str(date_last_str) + \" ]\"] + \\\n",
    "                                        [\"DOCTYPE [ \" + str(doctype_last) + \" ]\"]\n",
    "\n",
    "                        section_to_order = {}\n",
    "                        for sectionname in document:\n",
    "                            seckey = str(doctype_last)+\"\\t\"+str(sectionname)\n",
    "                            vl = section_to_idx[seckey]\n",
    "                            section_to_order[sectionname] = vl\n",
    "\n",
    "                        # sort section\n",
    "                        section_to_order = dict(sorted(section_to_order.items(), key=lambda x: x[1]))\n",
    "                        for sectionname in section_to_order:\n",
    "                            document_list.append(\"SECTION [ \"+sectionname+\" ]\")\n",
    "                            document_list.append(document[sectionname])\n",
    "\n",
    "                        target_folder = output_directory+\"/\"+str(dptment_last)+\"/\"+str(((pt_id_last//docperfile)+1)*docperfile)\n",
    "                        if not os.path.exists(target_folder):\n",
    "                            os.makedirs(target_folder)\n",
    "                            \n",
    "                        file = open(target_folder+\"/\"+pt_id_str+\".txt\", \"a\")\n",
    "                        file.write(\"\\n\".join(document_list)+\"\\n\\n\")\n",
    "                        file.close()\n",
    "\n",
    "                        document = {}\n",
    "\n",
    "            \n",
    "            content = ws['서식내용'][row]\n",
    "            content = preprocessing.text_preprocessing(content)\n",
    "    \n",
    "            # Collect Sections & contents\n",
    "            # heldout set patients only\n",
    "            zeros_cur = \"\".join([\"0\"]*(8-len(str(pt_id))))\n",
    "            pt_id_current_str = zeros_cur + str(pt_id)\n",
    "            if pt_id_current_str not in pools:\n",
    "                \"\"\"pt_id_current_str is not in heldout set pool\"\"\"\n",
    "            else:\n",
    "                #document.append(\"SECTION [ \" + str(section) + \" ]\")\n",
    "                for c in range(len(content)):\n",
    "                    content_sub = content[c].split(\"\\n\")\n",
    "                    for s in range(len(content_sub)):\n",
    "                        if content_sub[s]!=\"\":\n",
    "                            keysec = str(section).strip()\n",
    "                            if keysec not in document:\n",
    "                                document[keysec] = content_sub[s]\n",
    "                            else:\n",
    "                                document[keysec] = document[keysec]+\"\\n\"+content_sub[s]\n",
    "                            \n",
    "            \n",
    "            date_last = date\n",
    "            dptment_last = dptment\n",
    "            pt_id_last= pt_id\n",
    "            doctype_last = doctype\n",
    "            \n",
    "    \n",
    "        if len(document)!=0:\n",
    "            # patient id was not in heldout set pool\n",
    "            if pt_id_str not in pools:\n",
    "                \"\"\"pt_id_current_str is not in heldout set pool\"\"\"\n",
    "                document = {}\n",
    "\n",
    "            # patient id was in heldout set pool\n",
    "            else:\n",
    "                date_last_str = preprocessing.text_preprocessing(date_last)\n",
    "                date_last_str = \"\".join(date_last_str)\n",
    "                date_last_str = date_last_str.replace(\"\\n\", \" \")                    \n",
    "                document_list = [\"DATE [ \" + str(date_last_str) + \" ]\"] + \\\n",
    "                                [\"DOCTYPE [ \" + str(doctype_last) + \" ]\"]\n",
    "\n",
    "                # sort sections\n",
    "                section_to_order = {}\n",
    "                for sectionname in document:\n",
    "                    seckey = str(doctype_last)+\"\\t\"+str(sectionname)\n",
    "                    vl = section_to_idx[seckey]\n",
    "                    section_to_order[sectionname] = vl\n",
    "\n",
    "                section_to_order = dict(sorted(section_to_order.items(), key=lambda x: x[1]))\n",
    "\n",
    "                for sectionname in section_to_order:\n",
    "                    document_list.append(\"SECTION [ \"+sectionname+\" ]\")\n",
    "                    document_list.append(document[sectionname])\n",
    "\n",
    "                target_folder = output_directory+\"/\"+str(dptment_last)+\"/\"+str(((pt_id_last//docperfile)+1)*docperfile)\n",
    "                if not os.path.exists(target_folder):\n",
    "                    os.makedirs(target_folder)\n",
    "\n",
    "                zeros = \"\".join([\"0\"]*(8-len(str(pt_id_last))))\n",
    "                pt_id_str = zeros + str(pt_id_last)\n",
    "\n",
    "                file = open(target_folder+\"/\"+pt_id_str+\".txt\", \"a\")\n",
    "                file.write(\"\\n\".join(document_list)+\"\\n\\n\")\n",
    "                file.close()\n",
    "\n",
    "                document = {}\n",
    "\n",
    "#         break\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88028cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd44fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623038e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad244f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30284c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibert",
   "language": "python",
   "name": "multibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
